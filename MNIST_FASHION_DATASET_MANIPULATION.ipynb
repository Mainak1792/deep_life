{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPXOjZhZZ6J7yU4nC8Ys77f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mainak1792/deep_life/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UBDzdcaqg8z"
      },
      "source": [
        "**mnist fashion dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiV3HYTdraSz"
      },
      "source": [
        "import the library files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z17jqsnQs_SM",
        "outputId": "ee2d6526-ebac-477a-bf04-6e8722d01f20"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyeltr21tAcA"
      },
      "source": [
        "load the datsets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7zTB5xztAwF",
        "outputId": "5c40d22a-c9d6-4753-deb1-7ac311c780c1"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD7jKy4RtJWW"
      },
      "source": [
        "visualise the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "6jtKJh-stJqs",
        "outputId": "9b7faed5-8f11-4b34-ef7b-3f997e170750"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[25])\n",
        "print(training_labels[25])\n",
        "print(training_images[25])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0  51   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 139 214 218 220 164 206 243 233 205  93   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 130 253 225 226 233 229 232 230 219 227 249  63   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 203 237 221 222 221 222 219 220 224 218 233 191   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 232 237 224 225 224 224 222 221 225 218 224 253   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255 232 223 225 222 221 219 216 219 212 223 255  30   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   5 255 230 224 221 223 218 219 217 221 214 229 255  89   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  32 255 228 221 220 223 221 221 218 217 221 232 255 113   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  78 255 227 218 220 221 226 225 219 215 232 168 255 148   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 115 255 237 221 221 218 228 227 219 216 241 107 255 152   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 144 255 218 223 220 215 223 222 215 216 240 119 255 154   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 167 255 102 224 223 215 219 220 213 213 234 131 255 165   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 170 255  34 221 229 215 217 217 214 216 238 102 254 175   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 172 255  27 235 225 215 214 215 215 213 246 104 253 181   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 173 255  18 249 217 215 215 215 216 210 241  95 247 183   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 172 255  19 252 214 216 215 214 215 211 245 106 244 176   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 164 254  27 253 212 217 216 214 215 214 243 110 243 145   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 169 255  42 253 211 215 218 218 215 215 233 149 255 141   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 103 131  49 253 212 216 222 219 217 214 249 128 122  78   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  58 254 218 217 225 218 219 212 253 110   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   4   0  64 237 219 220 229 217 222 217 235 129   0   3   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  54 239 221 222 231 215 225 217 237 125   0   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  50 241 220 224 233 212 227 217 241 120   0   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  41 242 222 226 236 213 228 220 243 113   0   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  33 242 224 228 239 216 230 221 245  97   0   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3   0  13 237 224 226 235 208 226 218 246  65   0   3   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0 217 244 245 255 253 241 236 248  22   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 115 181 103  54 141 146 134 101   0   0   1   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h13UfGVesZGs"
      },
      "source": [
        "**Normalise_the_training_data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJgWV9kLscJK"
      },
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xnsQ-uysdGi"
      },
      "source": [
        "**Develop_structure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eydG1q-Cslik"
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sdg_yaosphj"
      },
      "source": [
        "**Define_the_loss_parameter**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9yfDeM4s0vi",
        "outputId": "6cdaa776-0881-4c2a-a9a6-33cf27aa1c20"
      },
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=60)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.9886 - accuracy: 0.2339\n",
            "Epoch 2/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4703 - accuracy: 0.8279\n",
            "Epoch 3/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3040 - accuracy: 0.8896\n",
            "Epoch 4/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2497 - accuracy: 0.9091\n",
            "Epoch 5/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2106 - accuracy: 0.9208\n",
            "Epoch 6/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9288\n",
            "Epoch 7/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1710 - accuracy: 0.9356\n",
            "Epoch 8/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1612 - accuracy: 0.9383\n",
            "Epoch 9/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1518 - accuracy: 0.9420\n",
            "Epoch 10/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1462 - accuracy: 0.9446\n",
            "Epoch 11/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1381 - accuracy: 0.9476\n",
            "Epoch 12/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1362 - accuracy: 0.9474\n",
            "Epoch 13/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1288 - accuracy: 0.9501\n",
            "Epoch 14/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1294 - accuracy: 0.9501\n",
            "Epoch 15/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1274 - accuracy: 0.9517\n",
            "Epoch 16/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1219 - accuracy: 0.9535\n",
            "Epoch 17/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1198 - accuracy: 0.9549\n",
            "Epoch 18/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1156 - accuracy: 0.9555\n",
            "Epoch 19/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1143 - accuracy: 0.9569\n",
            "Epoch 20/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1096 - accuracy: 0.9580\n",
            "Epoch 21/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1096 - accuracy: 0.9574\n",
            "Epoch 22/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1054 - accuracy: 0.9592\n",
            "Epoch 23/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1064 - accuracy: 0.9585\n",
            "Epoch 24/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1026 - accuracy: 0.9615\n",
            "Epoch 25/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0980 - accuracy: 0.9633\n",
            "Epoch 26/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0973 - accuracy: 0.9624\n",
            "Epoch 27/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0990 - accuracy: 0.9631\n",
            "Epoch 28/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0953 - accuracy: 0.9648\n",
            "Epoch 29/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0956 - accuracy: 0.9633\n",
            "Epoch 30/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0914 - accuracy: 0.9647\n",
            "Epoch 31/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0899 - accuracy: 0.9663\n",
            "Epoch 32/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0920 - accuracy: 0.9654\n",
            "Epoch 33/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0900 - accuracy: 0.9657\n",
            "Epoch 34/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0858 - accuracy: 0.9673\n",
            "Epoch 35/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0885 - accuracy: 0.9659\n",
            "Epoch 36/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0853 - accuracy: 0.9677\n",
            "Epoch 37/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0845 - accuracy: 0.9677\n",
            "Epoch 38/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0810 - accuracy: 0.9701\n",
            "Epoch 39/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0815 - accuracy: 0.9687\n",
            "Epoch 40/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0799 - accuracy: 0.9701\n",
            "Epoch 41/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0804 - accuracy: 0.9705\n",
            "Epoch 42/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0785 - accuracy: 0.9703\n",
            "Epoch 43/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0777 - accuracy: 0.9696\n",
            "Epoch 44/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0775 - accuracy: 0.9712\n",
            "Epoch 45/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0788 - accuracy: 0.9705\n",
            "Epoch 46/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0729 - accuracy: 0.9718\n",
            "Epoch 47/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0727 - accuracy: 0.9728\n",
            "Epoch 48/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0747 - accuracy: 0.9718\n",
            "Epoch 49/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0715 - accuracy: 0.9734\n",
            "Epoch 50/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0725 - accuracy: 0.9732\n",
            "Epoch 51/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0714 - accuracy: 0.9741\n",
            "Epoch 52/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0710 - accuracy: 0.9733\n",
            "Epoch 53/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0711 - accuracy: 0.9732\n",
            "Epoch 54/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0720 - accuracy: 0.9728\n",
            "Epoch 55/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0697 - accuracy: 0.9736\n",
            "Epoch 56/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0692 - accuracy: 0.9743\n",
            "Epoch 57/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0691 - accuracy: 0.9746\n",
            "Epoch 58/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0684 - accuracy: 0.9744\n",
            "Epoch 59/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0683 - accuracy: 0.9744\n",
            "Epoch 60/60\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0686 - accuracy: 0.9744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f432aaefd10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1x5ghess2Lz"
      },
      "source": [
        "Evaluate the on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sALu3yIxtqSH",
        "outputId": "25d1c075-b98d-429c-eb7a-3c3d1d6bfbdf"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.7955 - accuracy: 0.8751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7954714298248291, 0.8751000165939331]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6q6F4bA19uF",
        "outputId": "92128ba1-bb0a-45ca-cd32-bdbca4f5f56e"
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.7438333e-25 1.4412353e-32 4.1012839e-24 1.1904517e-28 4.5068098e-36 1.0374396e-13 1.3408365e-29 1.3055403e-11 1.4286850e-15 1.0000000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVd57Ezx2CML",
        "outputId": "37f83b33-b719-4ac6-984d-8ac52d6dd6c5"
      },
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQqacD5479Z1"
      },
      "source": [
        "**Training with more neurons**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-AR66r146eA",
        "outputId": "22146d56-af06-423c-87f9-1eef7c928853"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3034\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0712\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0446\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0318\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0221\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0664\n",
            "[4.28224373e-10 4.18588364e-08 1.15833934e-07 6.13964148e-05 1.82391062e-13 2.32437869e-09 5.87168660e-13 9.99938130e-01 1.47992232e-08 3.41555022e-07]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV-Bboin8J8F"
      },
      "source": [
        "without normalisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jjGh8Cd8YVr",
        "outputId": "5ecec93c-b433-452d-d6fe-01b429d74bb5"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3332\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0794\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0503\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0353\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0242\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0742\n",
            "[1.4652821e-09 1.6952945e-10 8.7499920e-08 9.9571650e-07 2.8368048e-14 1.3023443e-09 1.3055370e-14 9.9999893e-01 7.3622854e-09 1.8927724e-09]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0928kgA86Gl"
      },
      "source": [
        "**Final Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMCxhnlB9A4D",
        "outputId": "c8bea312-27a1-4bc6-9723-45c61d497c20"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss')<0.3):\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.5848\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3635\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3257\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3053\n",
            "\n",
            "Reached 60% accuracy so cancelling training!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f431e074890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}
